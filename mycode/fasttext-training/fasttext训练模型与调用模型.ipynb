{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0845a627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>txt</th>\n",
       "      <th>url</th>\n",
       "      <th>offensiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1q49</td>\n",
       "      <td>&gt; The difference in average earnings between m...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1wdh</td>\n",
       "      <td>The myth is that the \"gap\" is entirely based o...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza23qx</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2bw8</td>\n",
       "      <td>The assertion is that women get paid less for ...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2iji</td>\n",
       "      <td>You said in the OP that's not what they're mea...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id comment_id                                                txt  \\\n",
       "0  42g75o    cza1q49  > The difference in average earnings between m...   \n",
       "1  42g75o    cza1wdh  The myth is that the \"gap\" is entirely based o...   \n",
       "2  42g75o    cza23qx                                          [deleted]   \n",
       "3  42g75o    cza2bw8  The assertion is that women get paid less for ...   \n",
       "4  42g75o    cza2iji  You said in the OP that's not what they're mea...   \n",
       "\n",
       "                                                 url  offensiveness_score  \n",
       "0  https://www.reddit.com/r/changemyview/comments...               -0.083  \n",
       "1  https://www.reddit.com/r/changemyview/comments...               -0.022  \n",
       "2  https://www.reddit.com/r/changemyview/comments...                0.167  \n",
       "3  https://www.reddit.com/r/changemyview/comments...               -0.146  \n",
       "4  https://www.reddit.com/r/changemyview/comments...               -0.083  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/xiaoguzai/数据/kaggle有毒评论对比/ruddit/ruddit_with_text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab31a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "import emoji\n",
    "\n",
    "CUSTOM_TABLE = str.maketrans(\n",
    "    {\n",
    "        \"\\xad\": None,\n",
    "        \"\\x7f\": None,\n",
    "        \"\\ufeff\": None,\n",
    "        \"\\u200b\": None,\n",
    "        \"\\u200e\": None,\n",
    "        \"\\u202a\": None,\n",
    "        \"\\u202c\": None,\n",
    "        \"‘\": \"'\",\n",
    "        \"’\": \"'\",\n",
    "        \"`\": \"'\",\n",
    "        \"“\": '\"',\n",
    "        \"”\": '\"',\n",
    "        \"«\": '\"',\n",
    "        \"»\": '\"',\n",
    "        \"ɢ\": \"G\",\n",
    "        \"ɪ\": \"I\",\n",
    "        \"ɴ\": \"N\",\n",
    "        \"ʀ\": \"R\",\n",
    "        \"ʏ\": \"Y\",\n",
    "        \"ʙ\": \"B\",\n",
    "        \"ʜ\": \"H\",\n",
    "        \"ʟ\": \"L\",\n",
    "        \"ғ\": \"F\",\n",
    "        \"ᴀ\": \"A\",\n",
    "        \"ᴄ\": \"C\",\n",
    "        \"ᴅ\": \"D\",\n",
    "        \"ᴇ\": \"E\",\n",
    "        \"ᴊ\": \"J\",\n",
    "        \"ᴋ\": \"K\",\n",
    "        \"ᴍ\": \"M\",\n",
    "        \"Μ\": \"M\",\n",
    "        \"ᴏ\": \"O\",\n",
    "        \"ᴘ\": \"P\",\n",
    "        \"ᴛ\": \"T\",\n",
    "        \"ᴜ\": \"U\",\n",
    "        \"ᴡ\": \"W\",\n",
    "        \"ᴠ\": \"V\",\n",
    "        \"ĸ\": \"K\",\n",
    "        \"в\": \"B\",\n",
    "        \"м\": \"M\",\n",
    "        \"н\": \"H\",\n",
    "        \"т\": \"T\",\n",
    "        \"ѕ\": \"S\",\n",
    "        \"—\": \"-\",\n",
    "        \"–\": \"-\",\n",
    "    }\n",
    ")\n",
    "\n",
    "WORDS_REPLACER = [\n",
    "    (\"sh*t\", \"shit\"),\n",
    "    (\"s**t\", \"shit\"),\n",
    "    (\"f*ck\", \"fuck\"),\n",
    "    (\"fu*k\", \"fuck\"),\n",
    "    (\"f**k\", \"fuck\"),\n",
    "    (\"f*****g\", \"fucking\"),\n",
    "    (\"f***ing\", \"fucking\"),\n",
    "    (\"f**king\", \"fucking\"),\n",
    "    (\"p*ssy\", \"pussy\"),\n",
    "    (\"p***y\", \"pussy\"),\n",
    "    (\"pu**y\", \"pussy\"),\n",
    "    (\"p*ss\", \"piss\"),\n",
    "    (\"b*tch\", \"bitch\"),\n",
    "    (\"bit*h\", \"bitch\"),\n",
    "    (\"h*ll\", \"hell\"),\n",
    "    (\"h**l\", \"hell\"),\n",
    "    (\"cr*p\", \"crap\"),\n",
    "    (\"d*mn\", \"damn\"),\n",
    "    (\"stu*pid\", \"stupid\"),\n",
    "    (\"st*pid\", \"stupid\"),\n",
    "    (\"n*gger\", \"nigger\"),\n",
    "    (\"n***ga\", \"nigger\"),\n",
    "    (\"f*ggot\", \"faggot\"),\n",
    "    (\"scr*w\", \"screw\"),\n",
    "    (\"pr*ck\", \"prick\"),\n",
    "    (\"g*d\", \"god\"),\n",
    "    (\"s*x\", \"sex\"),\n",
    "    (\"a*s\", \"ass\"),\n",
    "    (\"a**hole\", \"asshole\"),\n",
    "    (\"a***ole\", \"asshole\"),\n",
    "    (\"a**\", \"ass\"),\n",
    "]\n",
    "\n",
    "REGEX_REPLACER = [\n",
    "    (re.compile(pat.replace(\"*\", \"\\*\"), flags=re.IGNORECASE), repl)\n",
    "    for pat, repl in WORDS_REPLACER\n",
    "]\n",
    "\n",
    "RE_SPACE = re.compile(r\"\\s\")\n",
    "RE_MULTI_SPACE = re.compile(r\"\\s+\")\n",
    "\n",
    "NMS_TABLE = dict.fromkeys(\n",
    "    i for i in range(sys.maxunicode + 1) if unicodedata.category(chr(i)) == \"Mn\"\n",
    ")\n",
    "\n",
    "HEBREW_TABLE = {i: \"א\" for i in range(0x0590, 0x05FF)}\n",
    "ARABIC_TABLE = {i: \"ا\" for i in range(0x0600, 0x06FF)}\n",
    "CHINESE_TABLE = {i: \"是\" for i in range(0x4E00, 0x9FFF)}\n",
    "KANJI_TABLE = {i: \"ッ\" for i in range(0x2E80, 0x2FD5)}\n",
    "HIRAGANA_TABLE = {i: \"ッ\" for i in range(0x3041, 0x3096)}\n",
    "KATAKANA_TABLE = {i: \"ッ\" for i in range(0x30A0, 0x30FF)}\n",
    "\n",
    "TABLE = dict()\n",
    "TABLE.update(CUSTOM_TABLE)\n",
    "TABLE.update(NMS_TABLE)\n",
    "# Non-english languages\n",
    "TABLE.update(CHINESE_TABLE)\n",
    "TABLE.update(HEBREW_TABLE)\n",
    "TABLE.update(ARABIC_TABLE)\n",
    "TABLE.update(HIRAGANA_TABLE)\n",
    "TABLE.update(KATAKANA_TABLE)\n",
    "TABLE.update(KANJI_TABLE)\n",
    "\n",
    "\n",
    "EMOJI_REGEXP = emoji.get_emoji_regexp()\n",
    "\n",
    "UNICODE_EMOJI_MY = {\n",
    "    k: f\" EMJ {v.strip(':').replace('_', ' ')} \"\n",
    "    for k, v in emoji.UNICODE_EMOJI_ALIAS_ENGLISH.items()\n",
    "}\n",
    "\n",
    "\n",
    "def my_demojize(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Modified version of the demojize function from emoji\n",
    "    \"\"\"\n",
    "\n",
    "    def replace(match):\n",
    "        return UNICODE_EMOJI_MY.get(match.group(0), match.group(0))\n",
    "\n",
    "    return re.sub(\"\\ufe0f\", \"\", EMOJI_REGEXP.sub(replace, string))\n",
    "\n",
    "\n",
    "def fix_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Expects a list of lower-cased tokens from TweeterTokenizer\n",
    "    \"\"\"\n",
    "    for token in tokens:\n",
    "        if token == \"gov't\" or token == \"govt\":\n",
    "            yield \"government\"\n",
    "        elif token == \"i'm\":\n",
    "            yield \"i\"\n",
    "            yield \"am\"\n",
    "        elif token.endswith(\"n't\"):\n",
    "            yield token[:-3]\n",
    "            yield \"not\"\n",
    "        elif token.endswith(\"'re\"):\n",
    "            yield token[:-3]\n",
    "            yield \"are\"\n",
    "        elif token.endswith(\"'ll\"):\n",
    "            yield token[:-3]\n",
    "            yield \"will\"\n",
    "        elif token.endswith(\"'ve\"):\n",
    "            yield token[:-3]\n",
    "            yield \"have\"\n",
    "        elif token.endswith(\"'s\"):\n",
    "            yield token[:-2]\n",
    "            yield \"'s\"\n",
    "        else:\n",
    "            yield token\n",
    "\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = my_demojize(text)\n",
    "    text = RE_SPACE.sub(\" \", text)\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = text.translate(TABLE)\n",
    "    text = RE_MULTI_SPACE.sub(\" \", text).strip()\n",
    "\n",
    "    for pattern, repl in REGEX_REPLACER:\n",
    "        text = pattern.sub(repl, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "\n",
    "    text = text.lower()\n",
    "    # Clean some punctutations\n",
    "    text = text.replace('\\n', ' \\n ')  \n",
    "    # Add space between pattern\n",
    "    text = re.sub(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', text)\n",
    "    # Replace repeating puncts more than 3 times to length of 3\n",
    "    text = re.sub(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1', text)    \n",
    "    # Add space around repeating puncts\n",
    "    text = re.sub(r'([*!?\\']+)',r' \\1 ', text)    \n",
    "    # patterns with repeating characters \n",
    "    # naaaahhhhhhh to naaaahh\n",
    "    text = re.sub(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', text)\n",
    "    # naaaahh to naaahh\n",
    "    text = re.sub(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', text)\n",
    "    # multiple spaces to one\n",
    "    text = re.sub(r'[ ]{2,}',' ', text).strip()   \n",
    "    text = normalize(text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b84930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=4)\n",
    "df['txt'] = df['txt'].parallel_apply(normalize)\n",
    "df['txt'] = df['txt'].parallel_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bad728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838\n"
     ]
    }
   ],
   "source": [
    "text_list = df['txt'].values.tolist()\n",
    "print(len(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c58cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>txt</th>\n",
       "      <th>url</th>\n",
       "      <th>offensiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1q49</td>\n",
       "      <td>the difference in average earnings between men...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1wdh</td>\n",
       "      <td>the myth is that the gap is entirely based on ...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza23qx</td>\n",
       "      <td>deleted</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2bw8</td>\n",
       "      <td>the assertion is that women get paid less for ...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2iji</td>\n",
       "      <td>you said in the op that s not what they re mea...</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id comment_id                                                txt  \\\n",
       "0  42g75o    cza1q49  the difference in average earnings between men...   \n",
       "1  42g75o    cza1wdh  the myth is that the gap is entirely based on ...   \n",
       "2  42g75o    cza23qx                                            deleted   \n",
       "3  42g75o    cza2bw8  the assertion is that women get paid less for ...   \n",
       "4  42g75o    cza2iji  you said in the op that s not what they re mea...   \n",
       "\n",
       "                                                 url  offensiveness_score  \n",
       "0  https://www.reddit.com/r/changemyview/comments...               -0.083  \n",
       "1  https://www.reddit.com/r/changemyview/comments...               -0.022  \n",
       "2  https://www.reddit.com/r/changemyview/comments...                0.167  \n",
       "3  https://www.reddit.com/r/changemyview/comments...               -0.146  \n",
       "4  https://www.reddit.com/r/changemyview/comments...               -0.083  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928aed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_text = []\n",
    "for currenttext in df['txt']:\n",
    "    my_train_text.append(currenttext.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d5eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416643, 2099800)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "model = FastText(vector_size=4, min_count=4)  # instantiate\n",
    "model.build_vocab(my_train_text)\n",
    "model.train(my_train_text, epochs=10, total_examples=len(my_train_text))  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4657938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单词user的词向量： [ 0.8211108 -1.0423776  2.2726233  1.1154736]\n"
     ]
    }
   ],
   "source": [
    "print(\"单词user的词向量：\", model.wv.get_vector('user'))\n",
    "model.save('/home/xiaoguzai/模型/fasttext-linear/ruddit_result.bin', separately=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a644489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load('/home/xiaoguzai/模型/fasttext-linear/ruddit_result.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c516b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char_wb', max_df=0.5, max_features=46000, min_df=3,\n",
       "                ngram_range=(3, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5), max_features = 46000)\n",
    "vec.fit(df['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb6a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "def splitter(text):\n",
    "    tokens = []\n",
    "    \n",
    "    for word in text.split(' '):\n",
    "        tokens.append(word)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def vectorizer(text):\n",
    "    tokens = splitter(text)\n",
    "    \n",
    "    x1 = vec.transform([text]).toarray()\n",
    "    x2 = np.mean(model.wv[tokens], axis = 0).reshape(1, -1)\n",
    "    x = np.concatenate([x1, x2], axis = -1).astype(np.float16)\n",
    "    del x1\n",
    "    del x2 \n",
    "    \n",
    "    #return x[0] \n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442357d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_list = []\n",
    "for currenttext in df.txt:\n",
    "    X_list.append(vectorizer(currenttext))\n",
    "    \n",
    "labels = df['offensiveness_score'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c52e4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.    ,  0.    ,  0.    , ..., -0.4456,  0.9937,  2.58  ],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4b5c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.083"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc23b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.8, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "regressor1 = Ridge(random_state=42,alpha=0.8)\n",
    "regressor1.fit(X_list,labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03271e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor = Ridge(random_state=42,alpha=0.8)\n",
    "#regressor.fit(comments_tr,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f08db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just read what you wrote; neither of the tw...</td>\n",
       "      <td>\\n\\nwhy should people have to read crap posted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"\\n\\nI don't know which \"\"personal attacks\"\" y...</td>\n",
       "      <td>\\n\\nwhy should people have to read crap posted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>\\nU POUR ADMIN, U UPDATE VANDAL COUNT, WHILE R...</td>\n",
       "      <td>Your relentless edit warring \\n\\nYour message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>\\n\\nFailure to follow the guidelines of WP:NO...</td>\n",
       "      <td>Against community and you don't know what devi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n\\nGet a encyclopedia you nerds......(kanich...</td>\n",
       "      <td>AND TO THE PARTY WHO FUCKS ME, FUCK U! I'LL BE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         less_toxic  \\\n",
       "0           1   I just read what you wrote; neither of the tw...   \n",
       "1           2  \"\\n\\nI don't know which \"\"personal attacks\"\" y...   \n",
       "2           5  \\nU POUR ADMIN, U UPDATE VANDAL COUNT, WHILE R...   \n",
       "3           9   \\n\\nFailure to follow the guidelines of WP:NO...   \n",
       "4          10   \\n\\nGet a encyclopedia you nerds......(kanich...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  \\n\\nwhy should people have to read crap posted...  \n",
       "1  \\n\\nwhy should people have to read crap posted...  \n",
       "2   Your relentless edit warring \\n\\nYour message...  \n",
       "3  Against community and you don't know what devi...  \n",
       "4  AND TO THE PARTY WHO FUCKS ME, FUCK U! I'LL BE...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('/home/xiaoguzai/数据/Kaggle Jigsaw Rate Severity of Toxic Comments/validation_true.csv')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f687def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['less_toxic'] = df_val['less_toxic'].parallel_apply(normalize)\n",
    "df_val['less_toxic'] = df_val['less_toxic'].parallel_apply(text_cleaning)\n",
    "df_val['more_toxic'] = df_val['more_toxic'].parallel_apply(normalize)\n",
    "df_val['more_toxic'] = df_val['more_toxic'].parallel_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5830e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_less_list = []\n",
    "df_val_more_list = []\n",
    "for current_text in df_val.less_toxic:\n",
    "    df_val_less_list.append(vectorizer(current_text))\n",
    "for current_text in df_val.more_toxic:\n",
    "    df_val_more_list.append(vectorizer(current_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0a6d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_less_result = regressor1.predict(df_val_less_list)\n",
    "df_val_more_result = regressor1.predict(df_val_more_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567ac14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.95"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((df_val_less_result < df_val_more_result).mean() * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa87abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
