{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference (please appreciate and upvote the original authors): \n",
    "- https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768\n",
    "- https://www.kaggle.com/samarthagarwal23/mega-b-ridge-to-the-top-0-84 \n",
    "- https://www.kaggle.com/leolu1998/jigsaw-ensemble-tfidf-bert\n",
    "- https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\n",
    "- https://www.kaggle.com/debarshichanda/0-816-jigsaw-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author by xiaoguzai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:46:03.259647Z",
     "iopub.status.busy": "2021-12-13T12:46:03.259295Z",
     "iopub.status.idle": "2021-12-13T12:46:04.491623Z",
     "shell.execute_reply": "2021-12-13T12:46:04.490912Z",
     "shell.execute_reply.started": "2021-12-13T12:46:03.259595Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "random_seed = 1\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗数据部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:46:04.494891Z",
     "iopub.status.busy": "2021-12-13T12:46:04.494382Z",
     "iopub.status.idle": "2021-12-13T12:46:15.188277Z",
     "shell.execute_reply": "2021-12-13T12:46:15.187382Z",
     "shell.execute_reply.started": "2021-12-13T12:46:04.494852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: pythonicforbert in /home/xiaoguzai/.local/lib/python3.9/site-packages (1.0.12)\r\n",
      "Requirement already satisfied: torch>=1.5.0 in /home/xiaoguzai/.local/lib/python3.9/site-packages (from pythonicforbert) (1.9.1+cu111)\r\n",
      "Requirement already satisfied: typing-extensions in /home/xiaoguzai/.local/lib/python3.9/site-packages (from torch>=1.5.0->pythonicforbert) (3.10.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pythonicforbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:46:15.190800Z",
     "iopub.status.busy": "2021-12-13T12:46:15.190447Z",
     "iopub.status.idle": "2021-12-13T12:46:16.346867Z",
     "shell.execute_reply": "2021-12-13T12:46:16.346140Z",
     "shell.execute_reply.started": "2021-12-13T12:46:15.190748Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data \n",
    "\n",
    "## Convert the label to SUM of all toxic labels (This might help with maintaining toxicity order of comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16299195, 4)\n"
     ]
    }
   ],
   "source": [
    "df_ = pd.read_csv(\"/home/xiaoguzai/数据/kaggle有毒评论对比/ruddit-pair/ruddit_pairs.csv\")  # create a dateframe based on a file\n",
    "\n",
    "print(df_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16299, 4)\n"
     ]
    }
   ],
   "source": [
    "frac_1 = 0.001\n",
    "df_ = df_.sample(frac=frac_1,random_state=random_seed).sample(frac=1,random_state=random_seed)\n",
    "print(df_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_[['txt1','sc1']].rename(columns={'txt1':'txt','sc1':'y'})\n",
    "df_2 = df_[['txt2','sc2']].rename(columns={'txt2':'txt','sc2':'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16299, 2)\n",
      "(16299, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_1.shape)\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15840661</th>\n",
       "      <td>Thats not as crazy as you make it sound. For example, In germany there is an industry wide agreement to not report on people commiting suicide by jumping in front of trains. And it made the numbers go down considerably. And i have not heard of any government pressure, its jsut the right thing to do</td>\n",
       "      <td>-0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300448</th>\n",
       "      <td>Deus Ex. I'll take an augment to fly, and be able to see through women's clothing..thank you.</td>\n",
       "      <td>-0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10486465</th>\n",
       "      <td>trying to come up with a test that proves the existence of god?\\n\\ngood luck with that ;)</td>\n",
       "      <td>-0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431023</th>\n",
       "      <td>Can you put the scientific method itself to this test?</td>\n",
       "      <td>-0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955218</th>\n",
       "      <td>I've heard this comparison - imagine you need to undergo brain surgery. Do you look for the surgeon you'd most like to have a beer or a conversation with? Hell no. You look for the most trained, skilled, and accomplished person for that particular job.</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                  txt  \\\n",
       "15840661  Thats not as crazy as you make it sound. For example, In germany there is an industry wide agreement to not report on people commiting suicide by jumping in front of trains. And it made the numbers go down considerably. And i have not heard of any government pressure, its jsut the right thing to do   \n",
       "6300448                                                                                                                                                                                                                 Deus Ex. I'll take an augment to fly, and be able to see through women's clothing..thank you.   \n",
       "10486465                                                                                                                                                                                                                    trying to come up with a test that proves the existence of god?\\n\\ngood luck with that ;)   \n",
       "5431023                                                                                                                                                                                                                                                        Can you put the scientific method itself to this test?   \n",
       "7955218                                                  I've heard this comparison - imagine you need to undergo brain surgery. Do you look for the surgeon you'd most like to have a beer or a conversation with? Hell no. You look for the most trained, skilled, and accomplished person for that particular job.   \n",
       "\n",
       "              y  \n",
       "15840661 -0.106  \n",
       "6300448  -0.043  \n",
       "10486465 -0.087  \n",
       "5431023  -0.681  \n",
       "7955218   0.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = min(df_1.y.min(),df_2.y.min())\n",
    "max_data = max(df_2.y.max(),df_2.y.max())\n",
    "df_1['y'] = (df_1['y']-min_data)/(max_data-min_data)\n",
    "df_2['y'] = (df_2['y']-min_data)/(max_data-min_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXJElEQVR4nO3df5Bd5V3H8fen4VdMkECDdzCJ3ThN1bSZUtwBOnX0AhaW1Gno2HbC0JLQ6FYFp2pGG3QcWigzdGyK0qHoVmJChzaN/WF2IJWJgTsMjgGSQlkSRFZIJWtKtAnRLW108esf90l7m+5mz95fh5vn85rZ2XOe8zzneb67937vueeeex5FBGZmlofXlT0AMzPrHid9M7OMOOmbmWXESd/MLCNO+mZmGTml7AGcyPz586Ovr6/p9t/97neZM2dO+wbUA3KLObd4wTHnopWYd+/e/Z8Rce5k217TSb+vr49du3Y13b5Wq1GtVts3oB6QW8y5xQuOORetxCzpW1Nt8+kdM7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjLymv5FrNp2RsSOsXnd/KX3vu+1dpfRr1gof6ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMlI46UuaJekJSfel9cWSHpU0KulLkk5L5aen9dG0va9hHzem8mclXdH2aMzM7IRmcqT/EeCZhvVPArdHxBuBw8CaVL4GOJzKb0/1kLQUWAm8GRgAPitpVmvDNzOzmSiU9CUtBN4F/HVaF3Ap8OVUZRNwVVpekdZJ2y9L9VcAmyPiaES8AIwCF7YhBjMzK6joN3L/HPgj4My0/nrg5YiYSOv7gQVpeQHwIkBETEg6kuovAHY27LOxzQ9IGgQGASqVCrVareAQf9z4+HhL7XtRbjFXZsPaZRPTV+yAsv7Ouf2PwTG307RJX9KvAQcjYrekattHcJyIGAKGAPr7+6OVyZA9mfLJ7zP3bmX9SDl3E9l3TbWUfnP7H4Njbqciz5Z3AO+WtBw4A/hJ4C+AeZJOSUf7C4GxVH8MWATsl3QKcBbwnYbyYxrbmJlZF0x7Tj8iboyIhRHRR/2D2Acj4hrgIeC9qdoqYGtaHk7rpO0PRkSk8pXp6p7FwBLgsbZFYmZm02rlffFHgc2SPgE8Adydyu8GPi9pFDhE/YWCiNgjaQuwF5gAro+IV1vo38zMZmhGST8iakAtLT/PJFffRMT3gfdN0f5W4NaZDtLMzNrD38g1M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLSDm3J7STTt+6+0vpd+2yUro161k+0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZWTapC/pDEmPSfqmpD2SPp7KN0p6QdKT6ef8VC5Jd0galfSUpAsa9rVK0nPpZ9UUXZqZWYcUuU7/KHBpRIxLOhV4RNLX07Y/jIgvH1f/Surz3y4BLgLuAi6SdA5wE9APBLBb0nBEHG5HIGZmNr0iE6NHRIyn1VPTT5ygyQrgntRuJzBP0nnAFcD2iDiUEv12YKC14ZuZ2Uwo4kT5O1WSZgG7gTcCd0bERyVtBN5O/Z3ADmBdRByVdB9wW0Q8ktruoD6JehU4IyI+kcr/FPheRHzquL4GgUGASqXyi5s3b246uPHxcebOndt0+15UVswjY0e63idAZTa89L1SumbZgrNK6deP6zy0EvMll1yyOyL6J9tW6DYMEfEqcL6kecDXJL0FuBH4NnAaMEQ9sd/c1Ah/tK+htD/6+/ujWq02va9arUYr7XtRWTGvLu02DBOsHynnbiL7rqmW0q8f13noVMwzunonIl4GHgIGIuJAOoVzFPgb4MJUbQxY1NBsYSqbqtzMzLqkyNU756YjfCTNBt4J/HM6T48kAVcBT6cmw8C16Sqei4EjEXEAeAC4XNLZks4GLk9lZmbWJUXeF58HbErn9V8HbImI+yQ9KOlcQMCTwG+l+tuA5cAo8ApwHUBEHJJ0C/B4qndzRBxqWyRmZjataZN+RDwFvG2S8kunqB/A9VNs2wBsmOEYzcysTfyNXDOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMlJk5qwzJD0m6ZuS9kj6eCpfLOlRSaOSviTptFR+elofTdv7GvZ1Yyp/VtIVHYvKzMwmVeRI/yhwaUS8FTgfGEjTIH4SuD0i3ggcBtak+muAw6n89lQPSUuBlcCbgQHgs2k2LjMz65Jpk36a/Hw8rZ6afgK4FPhyKt9EfZ5cgBVpnbT9sjSP7gpgc0QcjYgXqE+neGwydTMz64Iic+SSjsh3A28E7gT+FXg5IiZSlf3AgrS8AHgRICImJB0BXp/KdzbstrFNY1+DwCBApVKhVqvNLKIG4+PjLbXvRWXFvHbZxPSVOqAyu7y+y3ps+XGdh07FXCjpR8SrwPmS5gFfA36+7SP5YV9DwBBAf39/VKvVpvdVq9VopX0vKivm1evu73qfUE/460cKPYzbbt811VL69eM6D52KeUZX70TEy8BDwNuBeZKOPdsWAmNpeQxYBJC2nwV8p7F8kjZmZtYFRa7eOTcd4SNpNvBO4Bnqyf+9qdoqYGtaHk7rpO0PRkSk8pXp6p7FwBLgsTbFYWZmBRR5X3wesCmd138dsCUi7pO0F9gs6RPAE8Ddqf7dwOcljQKHqF+xQ0TskbQF2AtMANen00ZmZtYl0yb9iHgKeNsk5c8zydU3EfF94H1T7OtW4NaZD9PMzNrB38g1M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGyrknrdlJoK+k20lvHJhTSr92cvCRvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZaTIdImLJD0kaa+kPZI+kso/JmlM0pPpZ3lDmxsljUp6VtIVDeUDqWxU0rrOhGRmZlMpcsnmBLA2Ir4h6Uxgt6TtadvtEfGpxsqSllKfIvHNwE8D/yDpTWnzndTn2N0PPC5pOCL2tiMQMzObXpHpEg8AB9Lyf0t6BlhwgiYrgM0RcRR4Ic2Ve2xaxdE0zSKSNqe6TvpmZl0yoy9nSeqjPl/uo8A7gBskXQvsov5u4DD1F4SdDc3288MXiRePK79okj4GgUGASqVCrVabyRB/xPj4eEvte1FZMa9dNtH1PgEqs8vruyx+XOehUzEXTvqS5gJfAX4vIv5L0l3ALUCk3+uBD7U6oIgYAoYA+vv7o1qtNr2vWq1GK+17UVkxry7p26lrl02wfiSvL5ZvHJjjx3UGOhVzoWeLpFOpJ/x7I+KrABHxUsP2zwH3pdUxYFFD84WpjBOUm5lZFxS5ekfA3cAzEfHphvLzGqq9B3g6LQ8DKyWdLmkxsAR4DHgcWCJpsaTTqH/YO9yeMMzMrIgiR/rvAD4IjEh6MpX9MXC1pPOpn97ZB3wYICL2SNpC/QPaCeD6iHgVQNINwAPALGBDROxpWyRmZjatIlfvPAJokk3bTtDmVuDWScq3naidmZl1lr+Ra2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRorMnLVI0kOS9kraI+kjqfwcSdslPZd+n53KJekOSaOSnpJ0QcO+VqX6z0la1bmwzMxsMkVmzpoA1kbENySdCeyWtB1YDeyIiNskrQPWAR8FrqQ+ReIS4CLgLuAiSecANwH91Gfb2i1pOCIOtzuonI2MHSltknIze+2b9kg/Ig5ExDfS8n8DzwALgBXAplRtE3BVWl4B3BN1O4F5aT7dK4DtEXEoJfrtwEA7gzEzsxOb0Tl9SX3A24BHgUpEHEibvg1U0vIC4MWGZvtT2VTlZmbWJUVO7wAgaS7wFeD3IuK/pB9OmxsRISnaMSBJg8AgQKVSoVarNb2v8fHxltr3ospsWLtsouxhdE1u8UKej2vH3D6Fkr6kU6kn/Hsj4qup+CVJ50XEgXT65mAqHwMWNTRfmMrGgOpx5bXj+4qIIWAIoL+/P6rV6vFVCqvVarTSvhd95t6trB8p/Fre89Yum8gqXoCNA3Oye1zn+FzuVMxFrt4RcDfwTER8umHTMHDsCpxVwNaG8mvTVTwXA0fSaaAHgMslnZ2u9Lk8lZmZWZcUOUR6B/BBYETSk6nsj4HbgC2S1gDfAt6ftm0DlgOjwCvAdQARcUjSLcDjqd7NEXGoHUGYmVkx0yb9iHgE0BSbL5ukfgDXT7GvDcCGmQzQzMzax9/INTPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZKTJd4gZJByU93VD2MUljkp5MP8sbtt0oaVTSs5KuaCgfSGWjkta1PxQzM5tOkSP9jcDAJOW3R8T56WcbgKSlwErgzanNZyXNkjQLuBO4ElgKXJ3qmplZFxWZLvFhSX0F97cC2BwRR4EXJI0CF6ZtoxHxPICkzanu3pkP2czMmlVkYvSp3CDpWmAXsDYiDgMLgJ0NdfanMoAXjyu/aLKdShoEBgEqlQq1Wq3pAY6Pj7fUvhdVZsPaZRNlD6NrcosX8nxcO+b2aTbp3wXcAkT6vR74UDsGFBFDwBBAf39/VKvVpvdVq9VopX0v+sy9W1k/0spreW9Zu2wiq3gBNg7Mye5xneNzuVMxN/VsiYiXji1L+hxwX1odAxY1VF2YyjhBuZmZdUlTl2xKOq9h9T3AsSt7hoGVkk6XtBhYAjwGPA4skbRY0mnUP+wdbn7YZmbWjGmP9CV9EagC8yXtB24CqpLOp356Zx/wYYCI2CNpC/UPaCeA6yPi1bSfG4AHgFnAhojY0+5gzMzsxIpcvXP1JMV3n6D+rcCtk5RvA7bNaHRmZtZW/kaumVlGnPTNzDLipG9mlhEnfTOzjOT1rRazk8DI2BFWr7u/lL733fauUvq19vGRvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWkWmTvqQNkg5Kerqh7BxJ2yU9l36fncol6Q5Jo5KeknRBQ5tVqf5zklZ1JhwzMzuRIkf6G4GB48rWATsiYgmwI60DXEl9XtwlwCBwF9RfJKhPs3gRcCFw07EXCjMz655pk35EPAwcOq54BbApLW8CrmoovyfqdgLz0iTqVwDbI+JQRBwGtvPjLyRmZtZhzd5auRIRB9Lyt4FKWl4AvNhQb38qm6r8x0gapP4ugUqlQq1Wa3KIMD4+3lL7XlSZDWuXTZQ9jK7JLV4oN+aynk85Ppc7FXPL99OPiJAU7RhM2t8QMATQ398f1Wq16X3VajVaad+LPnPvVtaP5DNNwtplE1nFC+XGvO+aain95vhc7lTMzV6981I6bUP6fTCVjwGLGuotTGVTlZuZWRc1m/SHgWNX4KwCtjaUX5uu4rkYOJJOAz0AXC7p7PQB7uWpzMzMumja94iSvghUgfmS9lO/Cuc2YIukNcC3gPen6tuA5cAo8ApwHUBEHJJ0C/B4qndzRBz/4bCZmXXYtEk/Iq6eYtNlk9QN4Pop9rMB2DCj0ZmZWVv5G7lmZhlx0jczy4iTvplZRvK6wNnMWtK37v5S+t04MKeUfk9GTvodUNYTA2DtstK6NrMe4NM7ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLSEtJX9I+SSOSnpS0K5WdI2m7pOfS77NTuSTdIWlU0lOSLmhHAGZmVlw7jvQviYjzI6I/ra8DdkTEEmBHWge4EliSfgaBu9rQt5mZzUAnTu+sADal5U3AVQ3l90TdTmDescnVzcysO1Sf4bDJxtILwGEggL+KiCFJL0fEvLRdwOGImCfpPuC2iHgkbdsBfDQidh23z0Hq7wSoVCq/uHnz5qbHNz4+zty5c5tu36yRsSNd7/OYymx46Xuldd91ucULeca8+KxZpTyXy9RK/rrkkkt2N5x9+RGt3lr5lyJiTNJPAdsl/XPjxogISTN6VYmIIWAIoL+/P6rVatODq9VqtNK+WatLvbXyBOtH8rljdm7xQsYxP/LdUvred9u7Sum3U/mrpdM7ETGWfh8EvgZcCLx07LRN+n0wVR8DFjU0X5jKzMysS5pO+pLmSDrz2DJwOfA0MAysStVWAVvT8jBwbbqK52LgSEQcaHrkZmY2Y628R6wAX6uftucU4AsR8feSHge2SFoDfAt4f6q/DVgOjAKvANe10LeZmTWh6aQfEc8Db52k/DvAZZOUB3B9s/2ZmVnr/I1cM7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjed2U28xshvpKmh9j48CcjuzXR/pmZhlx0jczy8hJfXpnZOxIqVMXmpm91vhI38wsI11P+pIGJD0raVTSum73b2aWs64mfUmzgDuBK4GlwNWSlnZzDGZmOev2kf6FwGhEPB8R/wNsBlZ0eQxmZtlSferaLnUmvRcYiIjfSOsfBC6KiBsa6gwCg2n154BnW+hyPvCfLbTvRbnFnFu84Jhz0UrMb4iIcyfb8Jq7eicihoChduxL0q6I6G/HvnpFbjHnFi845lx0KuZun94ZAxY1rC9MZWZm1gXdTvqPA0skLZZ0GrASGO7yGMzMstXV0zsRMSHpBuABYBawISL2dLDLtpwm6jG5xZxbvOCYc9GRmLv6Qa6ZmZXL38g1M8uIk76ZWUZ6PulPd1sHSadL+lLa/qikvhKG2VYFYv4DSXslPSVph6Q3lDHOdip6+w5Jvy4pJPX85X1FYpb0/vS/3iPpC90eY7sVeGz/jKSHJD2RHt/Lyxhnu0jaIOmgpKen2C5Jd6S/x1OSLmi504jo2R/qHwb/K/CzwGnAN4Glx9X5HeAv0/JK4Etlj7sLMV8C/ERa/u0cYk71zgQeBnYC/WWPuwv/5yXAE8DZaf2nyh53F2IeAn47LS8F9pU97hZj/mXgAuDpKbYvB74OCLgYeLTVPnv9SL/IbR1WAJvS8peByySpi2Nst2ljjoiHIuKVtLqT+vchelnR23fcAnwS+H43B9chRWL+TeDOiDgMEBEHuzzGdisScwA/mZbPAv69i+Nru4h4GDh0giorgHuibicwT9J5rfTZ60l/AfBiw/r+VDZpnYiYAI4Ar+/K6DqjSMyN1lA/Uuhl08ac3vYuioiTZQKFIv/nNwFvkvSPknZKGuja6DqjSMwfAz4gaT+wDfjd7gytNDN9vk/rNXcbBmsfSR8A+oFfKXssnSTpdcCngdUlD6XbTqF+iqdK/d3cw5KWRcTLZQ6qw64GNkbEeklvBz4v6S0R8X9lD6xX9PqRfpHbOvygjqRTqL8l/E5XRtcZhW5lIelXgT8B3h0RR7s0tk6ZLuYzgbcANUn7qJ/7HO7xD3OL/J/3A8MR8b8R8QLwL9RfBHpVkZjXAFsAIuKfgDOo35jsZNX2W9f0etIvcluHYWBVWn4v8GCkT0h61LQxS3ob8FfUE36vn+eFaWKOiCMRMT8i+iKij/rnGO+OiF3lDLctijy2/476UT6S5lM/3fN8F8fYbkVi/jfgMgBJv0A96f9HV0fZXcPAtekqnouBIxFxoJUd9vTpnZjitg6SbgZ2RcQwcDf1t4Cj1D8wWVneiFtXMOY/A+YCf5s+s/63iHh3aYNuUcGYTyoFY34AuFzSXuBV4A8jomffxRaMeS3wOUm/T/1D3dW9fBAn6YvUX7jnp88pbgJOBYiIv6T+ucVyYBR4Bbiu5T57+O9lZmYz1Ound8zMbAac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGfl/QOmpOzA8wyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1.y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_2.y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:46:21.532350Z",
     "iopub.status.busy": "2021-12-13T12:46:21.532025Z",
     "iopub.status.idle": "2021-12-13T12:46:21.904620Z",
     "shell.execute_reply": "2021-12-13T12:46:21.903903Z",
     "shell.execute_reply.started": "2021-12-13T12:46:21.532314Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "def clean(data, col):\n",
    "\n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:46:21.907961Z",
     "iopub.status.busy": "2021-12-13T12:46:21.907705Z",
     "iopub.status.idle": "2021-12-13T12:46:21.930467Z",
     "shell.execute_reply": "2021-12-13T12:46:21.929853Z",
     "shell.execute_reply.started": "2021-12-13T12:46:21.907926Z"
    }
   },
   "source": [
    "# Test clean function\n",
    "test_clean_df = pd.DataFrame({\"text\":\n",
    "                              [\"heyy\\n\\nkkdsfj\",\n",
    "                               \"hi   how/are/you ???\",\n",
    "                               \"hey?????\",\n",
    "                               \"noooo!!!!!!!!!   comeone !! \",\n",
    "                              \"cooooooooool     brooooooooooo  coool brooo\",\n",
    "                              \"naaaahhhhhhh\"]})\n",
    "display(test_clean_df)\n",
    "clean(test_clean_df,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bert model to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:31.567420Z",
     "iopub.status.busy": "2021-12-13T12:47:31.566644Z",
     "iopub.status.idle": "2021-12-13T12:47:31.583494Z",
     "shell.execute_reply": "2021-12-13T12:47:31.582666Z",
     "shell.execute_reply.started": "2021-12-13T12:47:31.567376Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "from pythonicforbert import get_model_function,FullTokenizer\n",
    "with open('/home/xiaoguzai/数据/kaggle有毒评论对比/roberta-base/config.json','r',encoding='utf8')as fp:\n",
    "    json_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:31.585405Z",
     "iopub.status.busy": "2021-12-13T12:47:31.585133Z",
     "iopub.status.idle": "2021-12-13T12:47:31.594718Z",
     "shell.execute_reply": "2021-12-13T12:47:31.593782Z",
     "shell.execute_reply.started": "2021-12-13T12:47:31.585373Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self,model,config,n_labels):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(config.embedding_size,n_labels)\n",
    "        \n",
    "    def forward(self,input_ids):\n",
    "        mask_ids = torch.not_equal(input_ids,1)\n",
    "        #英文roberta padding=1\n",
    "        output = self.model(input_ids)\n",
    "        output = self.dropout(output)\n",
    "        output = output[:,0]\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "def train_compute_multilabel_loss(x1,x2,model,label1,label2):\n",
    "    logit1 = model(x1)\n",
    "    logit2 = model(x2)\n",
    "    logitmargin = logit1-logit2\n",
    "    labelmargin = label1-label2\n",
    "    loss_fn = torch.nn.MSELoss(reduce=True, size_average=True)\n",
    "    marginloss = loss_fn(logitmargin,labelmargin)\n",
    "    return marginloss\n",
    "\n",
    "def test_compute_multilabel_loss(x,model,label):\n",
    "    with torch.no_grad():\n",
    "        logit = model(x)\n",
    "    loss_fn = torch.nn.MSELoss(reduce=True, size_average=True)\n",
    "    mseloss = loss_fn(logit,label)\n",
    "    return mseloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数备选：平方差、绝对值差函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:31.596507Z",
     "iopub.status.busy": "2021-12-13T12:47:31.596069Z",
     "iopub.status.idle": "2021-12-13T12:47:31.718501Z",
     "shell.execute_reply": "2021-12-13T12:47:31.717806Z",
     "shell.execute_reply.started": "2021-12-13T12:47:31.596468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                             text  \\\n",
      "3497  It ' relevant USYD Department Music notable history notable alumni. The nature amalgamation means Arts Music unit continues operate independent department (albeit greater sharing resources (including lecturers students) two campuses). I believe history Arts Music notable enough warrant section a...   \n",
      "4669                                                                                      \" If seriously think \"\"described UK press best known starring\"\" somehow encapsulates information, engages readers, aesthetically pleasing simply \"\"starred\"\", spectacularly, utterly, ineptly clueless. 190.46.98.195 \"   \n",
      "5356                                                                                                                                                                                        If feel like bringing WP:RFC. You one trying change status quo article, I ' leave post (You ' notice I title change).   \n",
      "5835                                                                                                                                                                                                                                                                                Shut up, bitch. 38.116.200.66   \n",
      "8435                                                                                                                                                                                                                                                        Thanks ! Signed, Tenacious little shit. 206.124.6.222   \n",
      "\n",
      "             y  \n",
      "3497  0.000000  \n",
      "4669  0.000000  \n",
      "5356  0.000000  \n",
      "5835  0.714286  \n",
      "8435  0.285714  \n"
     ]
    }
   ],
   "source": [
    "current_df = pd.read_csv(\"/home/xiaoguzai/数据/抽取出几折数据/df_clean_fld0.csv\")\n",
    "print(current_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:31.719849Z",
     "iopub.status.busy": "2021-12-13T12:47:31.719606Z",
     "iopub.status.idle": "2021-12-13T12:47:32.445027Z",
     "shell.execute_reply": "2021-12-13T12:47:32.444307Z",
     "shell.execute_reply.started": "2021-12-13T12:47:31.719815Z"
    }
   },
   "source": [
    "total_text,total_label = [],[]\n",
    "for current_split in range(n_folds):\n",
    "    current_df = pd.read_csv(\"/home/xiaoguzai/数据/抽取出几折数据/df_clean_fld\"+str(current_split)+\".csv\")\n",
    "    total_text.append(current_df['text'].values.tolist())\n",
    "    total_label.append(current_df['y'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多折叠模型训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:32.446781Z",
     "iopub.status.busy": "2021-12-13T12:47:32.446532Z",
     "iopub.status.idle": "2021-12-13T12:47:37.854976Z",
     "shell.execute_reply": "2021-12-13T12:47:37.854183Z",
     "shell.execute_reply.started": "2021-12-13T12:47:32.446747Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenizer = FullTokenizer(vocab_file=vocab_file)\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/xiaoguzai/模型/roberta-english-base\")\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self,text1,text2,maxlen,label1,label2):\n",
    "        self.text1 = text1\n",
    "        self.text2 = text2\n",
    "        self.maxlen = maxlen\n",
    "        self.label1 = label1\n",
    "        self.label2 = label2\n",
    "        token_id1,token_id2 = [],[]\n",
    "        for index in tqdm(range(len(self.text1))):\n",
    "            current_text1 = text1[index]\n",
    "            current_id = tokenizer(current_text1)['input_ids']\n",
    "            #roberta begin:0,end:2\n",
    "            #current_id = tokenizer.convert_tokens_to_ids(current_token)\n",
    "            current_id = self.sequence_padding(current_id)\n",
    "            token_id1.append(current_id)\n",
    "            current_text2 = text2[index]\n",
    "            current_id = tokenizer(current_text2)['input_ids']\n",
    "            current_id = self.sequence_padding(current_id)\n",
    "            token_id2.append(current_id)\n",
    "        self.tensors = [torch.tensor(token_id1),torch.tensor(token_id2),\\\n",
    "                        torch.tensor(label1),torch.tensor(label2)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label1)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors)\n",
    "    \n",
    "    def sequence_padding(self,inputs,padding = 1):\n",
    "        length = self.maxlen\n",
    "        if len(inputs) > length:\n",
    "            inputs = inputs[:length-1]+[inputs[-1]]\n",
    "        #保留[sep]标志部分,\n",
    "        outputs = []\n",
    "        pad_width = (0,length-len(inputs))\n",
    "        x = np.pad(inputs,pad_width,'constant',constant_values=padding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:37.858153Z",
     "iopub.status.busy": "2021-12-13T12:47:37.856178Z",
     "iopub.status.idle": "2021-12-13T12:47:37.866215Z",
     "shell.execute_reply": "2021-12-13T12:47:37.865542Z",
     "shell.execute_reply.started": "2021-12-13T12:47:37.858123Z"
    }
   },
   "outputs": [],
   "source": [
    "#易错点：testdataset的内容需要跟classificationdataset的内容保持一致\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,text,maxlen):\n",
    "        self.text = text\n",
    "        self.maxlen = maxlen\n",
    "        token_id = []\n",
    "        for index in tqdm(range(len(self.text))):\n",
    "            current_text = text[index]\n",
    "            current_id = tokenizer(current_text)['input_ids']\n",
    "            #roberta begin:0,end:2\n",
    "            #current_id = tokenizer.convert_tokens_to_ids(current_token)\n",
    "            current_id = self.sequence_padding(current_id)\n",
    "            token_id.append(current_id)\n",
    "        self.token_id = token_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_id)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #return [tuple(tensor[index] for tensor in self.tensors)]\n",
    "        return self.token_id[index]\n",
    "    \n",
    "    def sequence_padding(self,inputs,padding=1):\n",
    "        #英文roberta padding=1\n",
    "        length = self.maxlen\n",
    "        if len(inputs) > length:\n",
    "            inputs = inputs[:length-1]+[inputs[-1]]\n",
    "        #保留[sep]标志部分\n",
    "        outputs = []\n",
    "        pad_width = (0,length-len(inputs))\n",
    "        x = np.pad(inputs,pad_width,'constant',constant_values=padding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:37.867971Z",
     "iopub.status.busy": "2021-12-13T12:47:37.867392Z",
     "iopub.status.idle": "2021-12-13T12:47:38.372236Z",
     "shell.execute_reply": "2021-12-13T12:47:38.371508Z",
     "shell.execute_reply.started": "2021-12-13T12:47:37.867932Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_data_df = pd.read_csv(\"/home/xiaoguzai/数据/Kaggle Jigsaw Rate Severity of Toxic Comments/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:47:38.373972Z",
     "iopub.status.busy": "2021-12-13T12:47:38.373731Z",
     "iopub.status.idle": "2021-12-13T14:12:05.349869Z",
     "shell.execute_reply": "2021-12-13T14:12:05.348925Z",
     "shell.execute_reply.started": "2021-12-13T12:47:38.373940Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "16299\n",
      "Done loading 197 ROBERTA weights from: /home/xiaoguzai/模型/hated-roberta/pytorch_model.bin. Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tclassifier.dense.weight\n",
      "\tclassifier.out_proj.bias\n",
      "\tclassifier.out_proj.weight\n",
      "\tclassifier.dense.bias\n",
      "\troberta.embeddings.position_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 16299/16299 [00:03<00:00, 4113.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化的学习率： 9e-06\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4075/4075 [11:04<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个epoch的学习率：0.000009\n",
      "Train Loss: 308.615051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4689.92it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:57<00:00, 11.06it/s]\n",
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4762.86it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:57<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_point = \n",
      "0.7019192718638702\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4075/4075 [11:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个epoch的学习率：0.000006\n",
      "Train Loss: 257.646851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4061.29it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:57<00:00, 10.95it/s]\n",
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 3978.56it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:56<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_point = \n",
      "0.7126038781163435\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4075/4075 [10:52<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个epoch的学习率：0.000005\n",
      "Train Loss: 254.934250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4218.66it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:56<00:00, 11.25it/s]\n",
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4205.42it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:56<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_point = \n",
      "0.7274436090225563\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4075/4075 [11:13<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3个epoch的学习率：0.000004\n",
      "Train Loss: 252.545929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4126.43it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:57<00:00, 11.04it/s]\n",
      "100%|███████████████████████████████████| 10108/10108 [00:02<00:00, 4129.14it/s]\n",
      "100%|█████████████████████████████████████████| 632/632 [00:56<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_point = \n",
      "0.7177483181638307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "bestpoint = []\n",
    "n_folds = 6\n",
    "#先单模单折\n",
    "\n",
    "r\"\"\"\n",
    "比较l1loss和mseloss的不同结果\n",
    "比较9e-6和2e-5的学习率\n",
    "\"\"\"\n",
    "\n",
    "less_toxic,more_toxic = valid_data_df['less_toxic'].values.tolist(),valid_data_df['more_toxic'].values.tolist()\n",
    "#print('less_toxic = ')\n",
    "#print(less_toxic[0:10])\n",
    "#print('more_toxic = ')\n",
    "#print(more_toxic[0:10])\n",
    "for current_slit in range(n_folds):\n",
    "    bestpoint.append(0.0)\n",
    "\n",
    "for current_split in range(1):\n",
    "    train_text1,train_text2,train_label1,train_label2 = [],[],[],[]\n",
    "    #单模单折所有数据作为训练集\n",
    "    #下面部分数据可能加入了\n",
    "    train_text1 = train_text1+df_1['txt'].values.tolist()\n",
    "    train_text2 = train_text2+df_2['txt'].values.tolist()\n",
    "    train_label1 = train_label1+df_1['y'].values.tolist()\n",
    "    train_label2 = train_label2+df_2['y'].values.tolist()\n",
    "    \n",
    "    #加入ruddit_data进行训练\n",
    "    print(len(train_text1))\n",
    "    \n",
    "    #def __init__(self,text,maxlen,labels)\n",
    "    \n",
    "    #加载官方bert模型\n",
    "    Roberta,robertaconfig,get_data = get_model_function('roberta-base')\n",
    "    config = robertaconfig(**json_data)\n",
    "    config.with_mlm = False\n",
    "    roberta = Roberta(config)\n",
    "    roberta = get_data(roberta,'/home/xiaoguzai/模型/hated-roberta/pytorch_model.bin')\n",
    "    model = ClassificationModel(roberta,config,1)\n",
    "    \n",
    "    train_dataset = ClassificationDataset(text1=train_text1,text2=train_text2,\\\n",
    "                                          maxlen=500,label1=train_label1,label2=train_label2)\n",
    "    train_loader = DataLoader(train_dataset,batch_size=4,shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=9e-6)\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch > 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2/(epoch+1)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    print(\"初始化的学习率：\", optimizer.defaults['lr'])\n",
    "    \n",
    "    for epoch in range(4):\n",
    "        print('epoch {}'.format(epoch))\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        #model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=20261.0split=0.pth')\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        model = model.to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "        loss_fn = torch.nn.L1Loss(reduce=True,size_average=True)\n",
    "        \n",
    "\n",
    "        for batch_token_id1,batch_token_id2,batch_label1,batch_label2 in tqdm(train_loader):\n",
    "            torch.set_printoptions(edgeitems=768)# 设置输出矩阵维度为768\n",
    "            batch_token_id1 = batch_token_id1.to(device)\n",
    "            batch_token_id2 = batch_token_id2.to(device)\n",
    "            batch_label1 = batch_label1.to(device)\n",
    "            batch_label2 = batch_label2.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = train_compute_multilabel_loss(batch_token_id1,batch_token_id2,model,batch_label1,batch_label2)\n",
    "            train_loss = train_loss+loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(\"第%d个epoch的学习率：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "        #注意必须从epoch=1开始，否则第0个没有学习率\n",
    "        print('Train Loss: {:.6f}'.format(train_loss))\n",
    "        \n",
    "        less_toxic_point,more_toxic_point = [],[]\n",
    "        right = []\n",
    "        test_dataset = TestDataset(less_toxic,maxlen=500)\n",
    "        test_loader = DataLoader(test_dataset,batch_size=16)\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        for batch_token in tqdm(test_loader):\n",
    "            batch_token = batch_token.to(device)\n",
    "            with torch.no_grad():\n",
    "                result_point = model(batch_token)\n",
    "                less_toxic_point = less_toxic_point+result_point.cpu().numpy().tolist()\n",
    "        test_dataset = TestDataset(more_toxic,maxlen=500)\n",
    "        test_loader = DataLoader(test_dataset,batch_size=16)\n",
    "        for batch_token in tqdm(test_loader):\n",
    "            batch_token = batch_token.to(device)\n",
    "            with torch.no_grad():\n",
    "                result_point = model(batch_token)\n",
    "                more_toxic_point = more_toxic_point+result_point.cpu().numpy().tolist()\n",
    "        right_point = sum([less_toxic_point[index] < more_toxic_point[index] for index in range(len(less_toxic_point))])\n",
    "        right_point = right_point/len(less_toxic_point)\n",
    "        print('right_point = ')\n",
    "        print(right_point)\n",
    "        if right_point >= bestpoint[current_split]:\n",
    "            bestpoint[current_split] = right_point\n",
    "            torch.save(model,'./best_score='+str(bestpoint[current_split])+'split='+str(current_split)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1151],\n",
       "        [0.1579],\n",
       "        [0.1420],\n",
       "        [0.1289],\n",
       "        [0.0858],\n",
       "        [0.0487],\n",
       "        [0.0439],\n",
       "        [0.1205],\n",
       "        [0.1031],\n",
       "        [0.0767],\n",
       "        [0.1107],\n",
       "        [0.1515]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12129.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(less_toxic_point)*2*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7177483181638307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T01:45:50.806900Z",
     "iopub.status.busy": "2021-12-13T01:45:50.806295Z",
     "iopub.status.idle": "2021-12-13T01:45:50.817278Z",
     "shell.execute_reply": "2021-12-13T01:45:50.816462Z",
     "shell.execute_reply.started": "2021-12-13T01:45:50.806862Z"
    }
   },
   "source": [
    "roberta.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-13T14:12:05.350715Z",
     "iopub.status.idle": "2021-12-13T14:12:05.351065Z",
     "shell.execute_reply": "2021-12-13T14:12:05.350907Z",
     "shell.execute_reply.started": "2021-12-13T14:12:05.350884Z"
    }
   },
   "outputs": [],
   "source": [
    "## 使用验证集计算出多折模型的权重内容\n",
    "model = torch.load('./best_score='+str(bestpoint[current_split])+'split='+str(current_split)+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation and Test data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-13T14:12:05.352076Z",
     "iopub.status.idle": "2021-12-13T14:12:05.352385Z",
     "shell.execute_reply": "2021-12-13T14:12:05.352245Z",
     "shell.execute_reply.started": "2021-12-13T14:12:05.352225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 7537/7537 [00:01<00:00, 3890.63it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:45<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "df_test = pd.read_csv(\"/home/xiaoguzai/数据/kaggle有毒评论对比/Jigsaw Rate Severity of Toxic Comments/comments_to_score.csv\")\n",
    "test_dataset = TestDataset(df_test['text'],maxlen=500)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "result = []\n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        result = result+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-13T14:12:05.353566Z",
     "iopub.status.idle": "2021-12-13T14:12:05.354138Z",
     "shell.execute_reply": "2021-12-13T14:12:05.353911Z",
     "shell.execute_reply.started": "2021-12-13T14:12:05.353888Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(\"/home/xiaoguzai/数据/kaggle有毒评论对比/Jigsaw Rate Severity of Toxic Comments/sample_submission.csv\")\n",
    "df_submission['score'] = result\n",
    "df_submission[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
