{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f099b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a7751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7d33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')\n",
    "df_val = pd.read_csv('/home/xiaoguzai/数据/Kaggle Jigsaw Rate Severity of Toxic Comments/validation_true.csv')\n",
    "df_sub = pd.read_csv(\"/home/xiaoguzai/数据/Kaggle Jigsaw Rate Severity of Toxic Comments/comments_to_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399761c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 7\n",
    "val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\n",
    "val_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\n",
    "test_preds_arr = np.zeros((df_sub.shape[0], n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee9ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythonicforbert\n",
    "from pythonicforbert import get_model_function,FullTokenizer\n",
    "import torch.nn as nn\n",
    "from pythonicforbert import get_model_function,FullTokenizer\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self,model,config,n_labels):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.fc = nn.Linear(config.embedding_size,n_labels)\n",
    "        \n",
    "    def forward(self,input_ids):\n",
    "        mask_ids = torch.not_equal(input_ids,1)\n",
    "        #英文roberta padding=1\n",
    "        output = self.model(input_ids)\n",
    "        if mask_ids is not None:\n",
    "            mask_ids = mask_ids[:,:,None].float()\n",
    "            output -= 1e-12*(1.0-mask_ids)\n",
    "        output = output[:,0]\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b49ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import RobertaTokenizer\n",
    "vocab_file = '/home/xiaoguzai/模型/roberta-english-base/vocab.json'\n",
    " \n",
    "merges_file = '/home/xiaoguzai/模型/roberta-english-base/merges.txt'\n",
    "tokenizer = RobertaTokenizer(vocab_file, merges_file)\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('../input/roberta-base')\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,text,maxlen):\n",
    "        self.text = text\n",
    "        self.maxlen = maxlen\n",
    "        token_id = []\n",
    "        for index in tqdm(range(len(self.text))):\n",
    "            current_text = text[index]\n",
    "            current_id = tokenizer(current_text)['input_ids']\n",
    "            #roberta begin:0,end\n",
    "            #current_id = tokenizer.convert_tokens_to_ids(current_token)\n",
    "            current_id = self.sequence_padding(current_id)\n",
    "            token_id.append(current_id)\n",
    "        self.token_id = token_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_id)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #return [tuple(tensor[index] for tensor in self.tensors)]\n",
    "        return self.token_id[index]\n",
    "    \n",
    "    def sequence_padding(self,inputs,padding=1):\n",
    "        #英文roberta padding=1\n",
    "        length = self.maxlen\n",
    "        if len(inputs) > length:\n",
    "            inputs = inputs[:length-1]+[inputs[-1]]\n",
    "        #保留[sep]标志部分\n",
    "        outputs = []\n",
    "        pad_width = (0,length-len(inputs))\n",
    "        x = np.pad(inputs,pad_width,'constant',constant_values=padding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0adedeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "roberta = get_model_function('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ba3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4806/4806 [00:02<00:00, 2228.40it/s]\n",
      "100%|█████████████████████████████████████| 4806/4806 [00:01<00:00, 2730.15it/s]\n",
      "100%|█████████████████████████████████████| 7537/7537 [00:02<00:00, 2697.09it/s]\n"
     ]
    }
   ],
   "source": [
    "lesstoxic_valid_dataset = TestDataset(df_val['less_toxic'],maxlen=500)\n",
    "lesstoxic_valid_loader = DataLoader(lesstoxic_valid_dataset,batch_size=16)\n",
    "moretoxic_valid_dataset = TestDataset(df_val['more_toxic'],maxlen=500)\n",
    "moretoxic_valid_loader = DataLoader(moretoxic_valid_dataset,batch_size=16)\n",
    "test_dataset = TestDataset(df_sub['text'],maxlen=500)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d3d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.75it/s]\n",
      "100%|█████████████████████████████████████████| 301/301 [00:28<00:00, 10.74it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:43<00:00, 10.74it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=0.8418643362463587seed=15.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "less_toxic1,more_toxic1 = [],[]\n",
    "result_toxic1 = []\n",
    "for batch_token in tqdm(lesstoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        less_toxic1 = less_toxic1+current_point.cpu().numpy().tolist()\n",
    "\n",
    "for batch_token in tqdm(moretoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        more_toxic1 = more_toxic1+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        result_toxic1 = result_toxic1+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0094fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.81it/s]\n",
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.82it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:43<00:00, 10.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=0.8416562630045776seed=4.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "less_toxic2,more_toxic2 = [],[]\n",
    "result_toxic2 = []\n",
    "for batch_token in tqdm(lesstoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        less_toxic2 = less_toxic2+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(moretoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        more_toxic2 = more_toxic2+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        result_toxic2 = result_toxic2+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3182291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.79it/s]\n",
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.78it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:43<00:00, 10.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=0.8410320432792343seed=5.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "less_toxic3,more_toxic3 = [],[]\n",
    "result_toxic3 = []\n",
    "for batch_token in tqdm(lesstoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        less_toxic3 = less_toxic3+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(moretoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        more_toxic3 = more_toxic3+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        result_toxic3 = result_toxic3+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04074ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 301/301 [00:27<00:00, 10.82it/s]\n",
      "100%|█████████████████████████████████████████| 301/301 [00:28<00:00, 10.62it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:45<00:00, 10.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=0.8401997503121099seed=1.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "less_toxic4,more_toxic4 = [],[]\n",
    "result_toxic4 = []\n",
    "for batch_token in tqdm(lesstoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        less_toxic4 = less_toxic4+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(moretoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        more_toxic4 = more_toxic4+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        result_toxic4 = result_toxic4+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c409e2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 301/301 [00:28<00:00, 10.66it/s]\n",
      "100%|█████████████████████████████████████████| 301/301 [00:28<00:00, 10.64it/s]\n",
      "100%|█████████████████████████████████████████| 472/472 [00:43<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/xiaoguzai/程序/kaggle有毒评论对比比赛/best_score=0.8395755305867666seed=8.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "less_toxic5,more_toxic5 = [],[]\n",
    "result_toxic5 = []\n",
    "for batch_token in tqdm(lesstoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        less_toxic5 = less_toxic5+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(moretoxic_valid_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        more_toxic5 = more_toxic5+current_point.cpu().numpy().tolist()\n",
    "        \n",
    "for batch_token in tqdm(test_loader):\n",
    "    batch_token = batch_token.to(device)\n",
    "    with torch.no_grad():\n",
    "        current_point = model(batch_token)\n",
    "        current_point = current_point.squeeze(-1)\n",
    "        result_toxic5 = result_toxic5+current_point.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "854b0a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_975078/2538804868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prin' is not defined"
     ]
    }
   ],
   "source": [
    "prin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759f171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "def calculate_data(i,j):\n",
    "    for k in range(0,31):\n",
    "        for u in range(0,31):\n",
    "            v = 100-i-j-k-u\n",
    "            less_toxic_wt = np.array(less_toxic1).dot(i)+np.array(less_toxic2).dot(j)+np.array(less_toxic3).dot(k)+\\\n",
    "                            np.array(less_toxic4).dot(u)+np.array(less_toxic5).dot(v)\n",
    "            #less_toxic_wt = i*less_toxic1 + j*less_toxic2 + k*less_toxic3\n",
    "            more_toxic_wt = np.array(more_toxic1).dot(i)+np.array(more_toxic2).dot(j)+np.array(more_toxic3).dot(k)+\\\n",
    "                            np.array(more_toxic4).dot(u)+np.array(more_toxic5).dot(v)\n",
    "            wts_acc.append((i,j,k,u,v,\n",
    "                        np.round((less_toxic_wt < more_toxic_wt).mean() * 100,2))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5736efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 31/31 [24:40<00:00, 47.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502 second\n"
     ]
    }
   ],
   "source": [
    "wts_acc = multiprocessing.Manager().list()\n",
    "\n",
    "#multiprocessing.Value,进程间共享这个list\n",
    "#multiprocessing.Manager().dict()/list(range(5))\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(0,31)):\n",
    "    for j in range(0,31):\n",
    "        #pool.apply_async(calculate_data,(i,j,))\n",
    "        p = multiprocessing.Process(target=calculate_data,args=(i,j,))\n",
    "        p.start()\n",
    "        p.join()\n",
    "\n",
    "sorted(wts_acc, key=lambda x:x[5], reverse=True)[:5]\n",
    "#新的结果不能使用w1,w2,w3，因为w1,w2,w3要作为最后的结果内容\n",
    "print('%d second'%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "688ec10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wts_acc = list(wts_acc)\n",
    "print(wts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99381d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2,w3,w4,w5,_ = sorted(wts_acc, key=lambda x:x[5], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d69f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 24.000000,w2 = 12.000000,w3 = 30.000000,w4 = 2.000000,w5 = 32.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('w1 = %f,w2 = %f,w3 = %f,w4 = %f,w5 = %f\\n'%(w1,w2,w3,w4,w5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ed9b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12, 30, 2, 32, 85.16),\n",
       " (21, 17, 30, 2, 30, 85.14),\n",
       " (22, 14, 30, 1, 33, 85.14),\n",
       " (24, 13, 30, 1, 32, 85.14),\n",
       " (24, 13, 30, 2, 31, 85.14)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wts_acc, key=lambda x:x[5], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbee727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
