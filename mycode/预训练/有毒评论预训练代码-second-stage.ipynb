{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9677155d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: pythonicforbert in /home/xiaoguzai/.local/lib/python3.9/site-packages (1.0.12)\r\n",
      "Requirement already satisfied: torch>=1.5.0 in /home/xiaoguzai/.local/lib/python3.9/site-packages (from pythonicforbert) (1.9.1+cu111)\r\n",
      "Requirement already satisfied: typing-extensions in /home/xiaoguzai/.local/lib/python3.9/site-packages (from torch>=1.5.0->pythonicforbert) (3.10.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "random_seed = 2\n",
    "frac_1 = 0.001\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch(random_seed)\n",
    "\n",
    "!pip install pythonicforbert\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth=300\n",
    "\n",
    "df_ = pd.read_csv(\"/home/xiaoguzai/数据/kaggle有毒评论对比/ruddit/ruddit_with_text.csv\")  # create a dateframe based on a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22112ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>txt</th>\n",
       "      <th>url</th>\n",
       "      <th>offensiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1q49</td>\n",
       "      <td>&gt; The difference in average earnings between men and women can be explained by taking into account relevant factors.\\n\\nSo it isn't a myth, you just feel that you can explain it.</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza1q49/</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza1wdh</td>\n",
       "      <td>The myth is that the \"gap\" is entirely based on the sex of the  person.</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza1wdh/</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza23qx</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza23qx/</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2bw8</td>\n",
       "      <td>The assertion is that women get paid less for the *same* jobs, and that they get paid less *because* they are women.</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza2bw8/</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42g75o</td>\n",
       "      <td>cza2iji</td>\n",
       "      <td>You said in the OP that's not what they're measuring. They're measuring aggregate. \\n\\nAs entertainers, women make less. Isn't that what JLaw was complaining about?</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza2iji/</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id comment_id  \\\n",
       "0  42g75o    cza1q49   \n",
       "1  42g75o    cza1wdh   \n",
       "2  42g75o    cza23qx   \n",
       "3  42g75o    cza2bw8   \n",
       "4  42g75o    cza2iji   \n",
       "\n",
       "                                                                                                                                                                                  txt  \\\n",
       "0  > The difference in average earnings between men and women can be explained by taking into account relevant factors.\\n\\nSo it isn't a myth, you just feel that you can explain it.   \n",
       "1                                                                                                            The myth is that the \"gap\" is entirely based on the sex of the  person.    \n",
       "2                                                                                                                                                                           [deleted]   \n",
       "3                                                               The assertion is that women get paid less for the *same* jobs, and that they get paid less *because* they are women.    \n",
       "4                You said in the OP that's not what they're measuring. They're measuring aggregate. \\n\\nAs entertainers, women make less. Isn't that what JLaw was complaining about?   \n",
       "\n",
       "                                                                                                    url  \\\n",
       "0  https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza1q49/   \n",
       "1  https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza1wdh/   \n",
       "2  https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza23qx/   \n",
       "3  https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza2bw8/   \n",
       "4  https://www.reddit.com/r/changemyview/comments/42g75o/cmv_the_so_called_wage_gap_is_a_myth//cza2iji/   \n",
       "\n",
       "   offensiveness_score  \n",
       "0               -0.083  \n",
       "1               -0.022  \n",
       "2                0.167  \n",
       "3               -0.146  \n",
       "4               -0.083  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87a8572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5838, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_.shape) \n",
    "df_['y'] = df_['offensiveness_score']\n",
    "\n",
    "\n",
    "min_data = df_.y.min()\n",
    "max_data = df_.y.max()\n",
    "df_['y'] = (df_['y']-min_data)/(max_data-min_data)\n",
    "df_.y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3685ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "from nezha_pretraining import nezha_pretraining_store_id_data\n",
    "\n",
    "def sequence_padding(inputs,maxlen,padding = 0):\n",
    "    length = maxlen\n",
    "    pad_width = [(0,0) for _ in np.shape(inputs[0])]\n",
    "    #print('pad_width = ')\n",
    "    #print(pad_width)\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        x = x[:length]\n",
    "        pad_width[0] = (0,length-len(x))\n",
    "        x = np.pad(x,pad_width,'constant',constant_values=padding)\n",
    "        outputs.append(x)\n",
    "    return np.array(outputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ccdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "from pythonicforbert import get_model_function,FullTokenizer\n",
    "with open('/home/xiaoguzai/模型/roberta-english-base/config.json','r',encoding='utf8')as fp:\n",
    "    json_data = json.load(fp)\n",
    "    \n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1d66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "#from transformers import AutoTokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"/home/xiaoguzai/模型/roberta-english-base\")\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"/home/xiaoguzai/模型/roberta-english-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a629e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roberta,robertaconfig,get_data = get_model_function('roberta-base')\n",
    "#_,robertaconfig,get_data = get_model_function('roberta-base')\n",
    "config = robertaconfig(**json_data)\n",
    "config.with_prediction = False\n",
    "roberta = Roberta(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c832c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 197 ROBERTA weights from: /home/xiaoguzai/模型/unbiased-toxic-roberta/pytorch_model.bin. Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\troberta.embeddings.position_ids\n",
      "\tclassifier.out_proj.weight\n",
      "\tclassifier.out_proj.bias\n",
      "\tclassifier.dense.bias\n",
      "\tclassifier.dense.weight\n"
     ]
    }
   ],
   "source": [
    "roberta = get_data(roberta,'/home/xiaoguzai/模型/unbiased-toxic-roberta/pytorch_model.bin')\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self,model,config,n_labels):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(config.embedding_size,n_labels)\n",
    "        \n",
    "    def forward(self,input_ids):\n",
    "        #mask_ids = torch.not_equal(input_ids,1)\n",
    "        #英文roberta padding=1\n",
    "        #print('input_ids = ')\n",
    "        #print(input_ids)\n",
    "        output = self.model(input_ids)\n",
    "        #print('output1 = ')\n",
    "        #print(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        #print('output2 = ')\n",
    "        #print(output)\n",
    "        return output\n",
    "model = ClassificationModel(roberta,config,config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237e0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = model.state_dict()\n",
    "current_data['fc.weight'] = current_data['model.robertaembeddings.word_embeddings_layer.weight']\n",
    "current_data['fc.bias'] = torch.zeros_like(current_data['fc.bias'])\n",
    "model.load_state_dict(current_data)\n",
    "#!!!pytorch中的linear权重自动翻转"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96081a5",
   "metadata": {},
   "source": [
    "## Mask掩码操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662ba77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_['txt'].values.tolist()\n",
    "label = df_['y'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a7c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_tqdm import p_map\n",
    "from functools import partial\n",
    "#并发遮盖掩码\n",
    "def nezha_pretraining_store_id_data(text_ids,label,begin,end):\n",
    "    input_ids,labels = [],[]\n",
    "    result_tuples = p_map(partial(random_mask,begin=begin,end=end),text_ids,label)\n",
    "    def get_tuple0(input_ids):\n",
    "        return input_ids[0]\n",
    "    def get_tuple1(input_ids):\n",
    "        return input_ids[1]\n",
    "    input_ids = p_map(get_tuple0,result_tuples)\n",
    "    labels = p_map(get_tuple1,result_tuples)\n",
    "    return input_ids,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a074de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask(text_ids,label,begin,end):\n",
    "    #对于只有id的脱敏数据进行ngram-mask\n",
    "    input_ids, output_ids = [], []\n",
    "    rands = np.random.random(len(text_ids))\n",
    "    idx=0\n",
    "    while idx<len(rands):\n",
    "        if rands[idx]<0.15:#需要mask\n",
    "            ngram=np.random.choice([1,2,3], p=[0.7,0.2,0.1])#若要mask，进行x_gram mask的概率\n",
    "            if ngram==3 and len(rands)<7:#太大的gram不要应用于过短文本\n",
    "                ngram=2\n",
    "            if ngram==2 and len(rands)<4:\n",
    "                ngram=1\n",
    "            L=idx+1\n",
    "            R=idx+ngram#最终需要mask的右边界（开）\n",
    "            while L<R and L<len(rands):\n",
    "                rands[L]=np.random.random()*0.15#强制mask\n",
    "                L+=1\n",
    "            idx=R\n",
    "            if idx<len(rands):\n",
    "                rands[idx]=1#禁止mask片段的下一个token被mask，防止一大片连续mask\n",
    "        idx+=1\n",
    "\n",
    "    sep_id = tokenizer.convert_tokens_to_ids([\"</s>\"])\n",
    "    sep_id = sep_id[0]\n",
    "    cls_id = tokenizer.convert_tokens_to_ids([\"<s>\"])\n",
    "    cls_id = cls_id[0]\n",
    "    mask_id = tokenizer.convert_tokens_to_ids([\"<mask>\"])\n",
    "    mask_id = mask_id[0]\n",
    "    #cls_id = 0,sep_id = 2,mask_id = ...\n",
    "    for index in range(len(text_ids)):\n",
    "        r = rands[index]\n",
    "        i = text_ids[index]\n",
    "        if text_ids[index] in [sep_id,cls_id,mask_id] or index == len(text_ids)-1:\n",
    "            input_ids.append(i)\n",
    "            output_ids.append(-100)\n",
    "            #保持原样不预测\n",
    "            continue\n",
    "        if r < 0.15 * 0.8:\n",
    "            input_ids.append(mask_id)\n",
    "            output_ids.append(i)#mask预测自己\n",
    "        elif r < 0.15 * 0.9:\n",
    "            input_ids.append(i)\n",
    "            output_ids.append(i)#自己预测自己\n",
    "        elif r < 0.15:\n",
    "            input_ids.append(np.random.randint(begin,end))\n",
    "            output_ids.append(i)#随机的一个词预测自己，随机词不会从特殊符号中选取，有小概率抽到自己\n",
    "        else:\n",
    "            input_ids.append(i)\n",
    "            output_ids.append(-100)#保持原样不预测\n",
    "    \n",
    "    prelabel = 'The point is'\n",
    "    pre_id = tokenizer(prelabel)['input_ids'][1:-1]\n",
    "    label = str(label)\n",
    "    label_id = tokenizer(label)['input_ids'][1:-1]+[sep_id]\n",
    "    rands = np.random.rand()\n",
    "    \n",
    "    input_label_id = pre_id\n",
    "    output_label_id = [-100]*len(pre_id)\n",
    "    \n",
    "    for index in range(len(label_id)):\n",
    "        i = label_id[index]\n",
    "        if i in [sep_id,cls_id,mask_id] or index == len(text_ids)-1:\n",
    "            input_label_id.append(i)\n",
    "            output_label_id.append(-100)\n",
    "            #保持原样不预测\n",
    "            continue\n",
    "        if rands < 0.15 * 0.8:\n",
    "            input_label_id.append(mask_id)\n",
    "            output_label_id.append(i)#mask预测自己\n",
    "        elif r < 0.15 * 0.9:\n",
    "            input_label_id.append(i)\n",
    "            output_label_id.append(i)#自己预测自己\n",
    "        elif r < 0.15:\n",
    "            input_label_id.append(np.random.randint(begin,end))\n",
    "            output_label_id.append(i)#随机的一个词预测自己，随机词不会从特殊符号中选取，有小概率抽到自己\n",
    "        else:\n",
    "            input_label_id.append(i)\n",
    "            output_label_id.append(-100)#保持原样不预测\n",
    "    \n",
    "    input_ids = input_ids+input_label_id\n",
    "    output_ids = output_ids+output_label_id\n",
    "    \n",
    "    return input_ids, output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472afe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = [1,2,3,4,5]\n",
    "result_ids,result_output_ids = random_mask(text_ids,0.133,0,config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29f3057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 133, 477, 16, 288, 4, 25037, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aae91f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc6e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c99a2c1f026444b978860f5d7efe086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93816ce77054b7f9ceac9c56410df10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21f9c135dd34217823406ced0a73d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_ids = []\n",
    "for index in range(len(text)):\n",
    "    current_text = text[index]\n",
    "    current_id = tokenizer(current_text)['input_ids']\n",
    "    text_ids.append(current_id)\n",
    "    \n",
    "pretrain_id,pretrain_label = nezha_pretraining_store_id_data(text_ids,label,0,config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdd2f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (model): Roberta(\n",
       "    (robertaembeddings): Embeddings(\n",
       "      (word_embeddings_layer): Embedding(50265, 768)\n",
       "      (segment_embeddings_layer): Embedding(1, 768)\n",
       "      (position_embeddings_layer): Embedding(514, 768)\n",
       "      (layer_normalization): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (roberta_encoder_layer): ModuleList(\n",
       "      (0): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (6): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (8): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (9): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (10): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (11): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=50265, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafd49b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  15698,\n",
       "  20,\n",
       "  2249,\n",
       "  11,\n",
       "  674,\n",
       "  50264,\n",
       "  227,\n",
       "  604,\n",
       "  8,\n",
       "  390,\n",
       "  64,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  602,\n",
       "  50264,\n",
       "  1316,\n",
       "  4249,\n",
       "  2433,\n",
       "  50264,\n",
       "  50264,\n",
       "  50118,\n",
       "  2847,\n",
       "  24,\n",
       "  965,\n",
       "  75,\n",
       "  10,\n",
       "  17721,\n",
       "  6,\n",
       "  47,\n",
       "  95,\n",
       "  619,\n",
       "  14,\n",
       "  47,\n",
       "  64,\n",
       "  3922,\n",
       "  24,\n",
       "  4,\n",
       "  2,\n",
       "  133,\n",
       "  477,\n",
       "  16,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  2],\n",
       " [0,\n",
       "  133,\n",
       "  17721,\n",
       "  16,\n",
       "  14,\n",
       "  5,\n",
       "  22,\n",
       "  29183,\n",
       "  113,\n",
       "  16,\n",
       "  4378,\n",
       "  716,\n",
       "  50264,\n",
       "  5,\n",
       "  50264,\n",
       "  9,\n",
       "  50264,\n",
       "  1437,\n",
       "  621,\n",
       "  4,\n",
       "  50264,\n",
       "  2,\n",
       "  133,\n",
       "  477,\n",
       "  16,\n",
       "  288,\n",
       "  4,\n",
       "  38888,\n",
       "  1558,\n",
       "  31782,\n",
       "  1922,\n",
       "  24108,\n",
       "  3103,\n",
       "  6232,\n",
       "  2],\n",
       " [0,\n",
       "  10975,\n",
       "  2794,\n",
       "  36140,\n",
       "  742,\n",
       "  2,\n",
       "  133,\n",
       "  477,\n",
       "  16,\n",
       "  288,\n",
       "  4,\n",
       "  37402,\n",
       "  23417,\n",
       "  3414,\n",
       "  5714,\n",
       "  37020,\n",
       "  3079,\n",
       "  2],\n",
       " [0,\n",
       "  133,\n",
       "  19395,\n",
       "  16,\n",
       "  14,\n",
       "  390,\n",
       "  120,\n",
       "  1199,\n",
       "  540,\n",
       "  13,\n",
       "  5,\n",
       "  1009,\n",
       "  50264,\n",
       "  23432,\n",
       "  1315,\n",
       "  6,\n",
       "  50264,\n",
       "  14,\n",
       "  51,\n",
       "  120,\n",
       "  50264,\n",
       "  50264,\n",
       "  1009,\n",
       "  13437,\n",
       "  3226,\n",
       "  51,\n",
       "  32,\n",
       "  390,\n",
       "  4,\n",
       "  1437,\n",
       "  2,\n",
       "  133,\n",
       "  477,\n",
       "  16,\n",
       "  288,\n",
       "  4,\n",
       "  34991,\n",
       "  2545,\n",
       "  1549,\n",
       "  2546,\n",
       "  2831,\n",
       "  4390,\n",
       "  1360,\n",
       "  2022,\n",
       "  2],\n",
       " [0,\n",
       "  1185,\n",
       "  26,\n",
       "  11,\n",
       "  5,\n",
       "  24839,\n",
       "  14,\n",
       "  18,\n",
       "  45,\n",
       "  99,\n",
       "  51,\n",
       "  214,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  214,\n",
       "  50264,\n",
       "  13884,\n",
       "  4,\n",
       "  1437,\n",
       "  50264,\n",
       "  50264,\n",
       "  1620,\n",
       "  12043,\n",
       "  268,\n",
       "  6,\n",
       "  390,\n",
       "  146,\n",
       "  540,\n",
       "  4,\n",
       "  26421,\n",
       "  75,\n",
       "  14,\n",
       "  99,\n",
       "  344,\n",
       "  22532,\n",
       "  21,\n",
       "  13689,\n",
       "  59,\n",
       "  116,\n",
       "  2,\n",
       "  133,\n",
       "  477,\n",
       "  16,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  50264,\n",
       "  2]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_id[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5672455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  674,\n",
       "  1107,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  28,\n",
       "  2002,\n",
       "  30,\n",
       "  -100,\n",
       "  88,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  4,\n",
       "  50118,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  288,\n",
       "  4,\n",
       "  3897,\n",
       "  26629,\n",
       "  2545,\n",
       "  1549,\n",
       "  2546,\n",
       "  2831,\n",
       "  39190,\n",
       "  -100],\n",
       " [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  5,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  15,\n",
       "  -100,\n",
       "  2099,\n",
       "  -100,\n",
       "  5,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  1437,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100],\n",
       " [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  288,\n",
       "  4,\n",
       "  37402,\n",
       "  23417,\n",
       "  3414,\n",
       "  -100,\n",
       "  37020,\n",
       "  3079,\n",
       "  -100],\n",
       " [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  390,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  41690,\n",
       "  3226,\n",
       "  -100,\n",
       "  -100,\n",
       "  8,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  1199,\n",
       "  540,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100],\n",
       " [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  24839,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  14978,\n",
       "  4,\n",
       "  252,\n",
       "  -100,\n",
       "  14978,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  50118,\n",
       "  50118,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  288,\n",
       "  4,\n",
       "  3897,\n",
       "  26629,\n",
       "  2545,\n",
       "  1549,\n",
       "  2546,\n",
       "  2831,\n",
       "  39190,\n",
       "  -100]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_label[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af9d1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self,pretrain_id,pretrain_label,maxlen):\n",
    "        result_id,result_label = [],[]\n",
    "        self.pretrain_id = pretrain_id\n",
    "        self.maxlen = maxlen\n",
    "        for index in tqdm(range(len(pretrain_id))):\n",
    "            current_id = pretrain_id[index]\n",
    "            current_id = self.sequence_padding(current_id,padding=1)\n",
    "            result_id.append(current_id)\n",
    "            current_label = pretrain_label[index]\n",
    "            current_label = self.sequence_padding(current_label,padding=-100)\n",
    "            #!!!注意两个padding不一样，输入的current_id的padding只能为1\n",
    "            result_label.append(current_label)\n",
    "        self.tensors = [torch.tensor(result_id),torch.tensor(result_label)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pretrain_id)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors)\n",
    "    \n",
    "    def sequence_padding(self,inputs,padding = -100):\n",
    "        length = self.maxlen\n",
    "        if len(inputs) > length:\n",
    "            inputs = inputs[:length-1]+[inputs[-1]]\n",
    "        #保留[sep]标志部分,\n",
    "        outputs = []\n",
    "        pad_width = (0,length-len(inputs))\n",
    "        x = np.pad(inputs,pad_width,'constant',constant_values=padding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "045f918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "365b214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (model): Roberta(\n",
       "    (robertaembeddings): Embeddings(\n",
       "      (word_embeddings_layer): Embedding(50265, 768)\n",
       "      (segment_embeddings_layer): Embedding(1, 768)\n",
       "      (position_embeddings_layer): Embedding(514, 768)\n",
       "      (layer_normalization): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (roberta_encoder_layer): ModuleList(\n",
       "      (0): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (6): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (8): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (9): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (10): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (11): Transformer(\n",
       "        (attention): AttentionLayer(\n",
       "          (query_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dense1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=50265, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a2cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 5838/5838 [00:00<00:00, 31463.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [02:56<00:00,  8.29it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.454385, Acc: 16.874659\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [02:57<00:00,  8.22it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.649304, Acc: 18.489727\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [02:57<00:00,  8.25it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.234459, Acc: 19.946575\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.879369, Acc: 21.497261\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.564157, Acc: 23.108219\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.248238, Acc: 24.909590\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.969504, Acc: 26.489042\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.716607, Acc: 28.175343\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.473832, Acc: 29.682877\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.280374, Acc: 31.098631\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.100978, Acc: 32.382195\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.969972, Acc: 33.382877\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.831205, Acc: 34.522602\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.718070, Acc: 35.434933\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.634324, Acc: 36.222603\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.560042, Acc: 36.893837\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.498450, Acc: 37.481506\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.446191, Acc: 37.975342\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.402820, Acc: 38.393837\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.362489, Acc: 38.846577\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.327845, Acc: 39.151371\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.301393, Acc: 39.364384\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.278926, Acc: 39.604111\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.256301, Acc: 39.779453\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.238119, Acc: 39.956165\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.222693, Acc: 40.066441\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.201600, Acc: 40.234249\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.193538, Acc: 40.328083\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.174715, Acc: 40.465755\n",
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████\u001b[0m| 1460/1460 [03:01<00:00,  8.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.161014, Acc: 40.635616\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=9e-6)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "import collections\n",
    "#torch.cuda.set_device(0)\n",
    "#torch.cuda.set_device(0)\n",
    "checkpoint = torch.load('/home/xiaoguzai/模型/toxic-comment预训练结果/labeled_data+model_epoch=170.pth')\n",
    "newcheckpoint = collections.OrderedDict()\n",
    "for k,v in checkpoint.items():\n",
    "     newcheckpoint[k[7:]] = checkpoint[k]\n",
    "#print(newcheckpoint)\n",
    "model.load_state_dict(newcheckpoint)\n",
    "#model.load_state_dict('/home/xiaoguzai/模型/toxic-comment预训练结果/labeled_data+model_epoch=170.pth')\n",
    "#model = torch.load('/home/xiaoguzai/模型/toxic-comment预训练结果/labeled_data+model_epoch=170.pth')\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "model.train()\n",
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "best_loss = 999999999999\n",
    "best_accuracy = 0.0\n",
    "content_dataset = ClassificationDataset(pretrain_id,pretrain_label,maxlen=500)\n",
    "content_data_iter = DataLoader(content_dataset,batch_size=4,shuffle=True)\n",
    "for epoch in range(30):\n",
    "    print('epoch {}'.format(epoch+1))\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    content_dataset_len = len(content_data_iter)\n",
    "    for batch_token_ids,batch_labels in tqdm(content_data_iter,colour='blue'):\n",
    "        batch_token_ids = batch_token_ids.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_token_ids)\n",
    "        output = output.view(-1,config.vocab_size)\n",
    "        batch_labels = batch_labels.view(-1)\n",
    "        loss = loss_func(output,batch_labels)\n",
    "        train_loss += loss\n",
    "        pred = torch.max(output, 1)[1]\n",
    "        train_correct = (pred == batch_labels).sum()\n",
    "        train_acc += train_correct\n",
    "        #scaler.scale(loss).backward()\n",
    "        #scaler.step(optimizer)\n",
    "        #scaler.update()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss/content_dataset_len, train_acc/content_dataset_len))\n",
    "    current_loss = train_loss/content_dataset_len\n",
    "    current_accuracy = train_acc/content_dataset_len\n",
    "    torch.save(model.state_dict(),'/home/xiaoguzai/模型/toxic-comment second pretrain sequence/'+'the_next_epoch_tmodel_epoch='+str(epoch+171)+'.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed52b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
